# Copyright 2023 LIN Yi. All Rights Reserved.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     http://www.apache.org/licenses/LICENSE-2.0
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

import torch
import retro
from transformers import AutoTokenizer, AutoModelForCausalLM
from street_fighter_custom_wrapper import StreetFighterCustomWrapper
from observer import Observer

# Configuration and Initialization
#MODEL = "mistralai/Mistral-7B-Instruct-v0.2"
MODEL = "mistral_finetune"
MODEL_NAME = "Mistral-7B-Instruct-v0.2"
game = "StreetFighterIISpecialChampionEdition-Genesis"
state = "Champion.Level12.RyuVsBison"
device = "cuda" if torch.cuda.is_available() else "cpu"
NUM_EPISODES = 30
RENDERING = False
RESET_ROUND = True

# Environment Setup
# env = retro.make(game=game, state=state, use_restricted_actions=retro.Actions.FILTERED, obs_type=retro.Observations.IMAGE)
# env = StreetFighterCustomWrapper(env, reset_round=True, rendering=False)

def make_env(game, state):
    def _init():
        env = retro.make(
            game=game, 
            state=state, 
            use_restricted_actions=retro.Actions.FILTERED,
            obs_type=retro.Observations.IMAGE
        )
        env = StreetFighterCustomWrapper(env, reset_round=RESET_ROUND, rendering=RENDERING)
        return env
    return _init

game = "StreetFighterIISpecialChampionEdition-Genesis"
env = make_env(game, state="Champion.Level12.RyuVsBison")()

# Model and Tokenizer
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model = AutoModelForCausalLM.from_pretrained(MODEL)
model.to(device)
model.eval()

# Observer for getting game state
RYU_GREY = [168, 168, 168]
GUILE_RED = [232, 32, 32]
observer = Observer(RYU_GREY, GUILE_RED)

#[punch, kick, move left, move right, crouch, crouch right, crouch left, jump, jump right, jump left]


def get_llm_actions(llm_output):
    #llm_output = llm_output.split("ASSISTANT")[1]
    llm_output = llm_output.lower()
    actions = [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]
    if "move left" in llm_output:
        actions[0][6] = 1.0
    if "move right" in llm_output:
        actions[0][7] = 1.0
    if "crouch" in llm_output:
        actions[0][5] = 1.0
    if "crouch right" in llm_output:
        actions[0][7] = 1.0
        actions[0][5] = 1.0
    if "crouch left" in llm_output:
        actions[0][6] = 1.0
        actions[0][5] = 1.0
    if "jump" in llm_output:
        actions[0][4] = 1.0
    if "jump right" in llm_output:
        actions[0][4] = 1.0
        actions[0][7] = 1.0
    if "jump left" in llm_output:
        actions[0][4] = 1.0
        actions[0][6] = 1.0
    if "punch" in llm_output:
        actions[0][11] = 1.0
        actions.append([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
    if "kick" in llm_output:
        actions[0][8] = 1.0
        actions.append([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
    # jump = [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]
    # punch = [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.] -> [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]
    # quick punch = [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.] -> [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]
    # heavy punch = [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.] -> [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]
    # kick = [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.] -> [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]
    # quick kick = [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.] -> [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]
    # heavy kick = [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.] -> [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]
    return actions


def extract_action_from_response(response, actions_list):
    """
    Extracts a single action from the response by isolating the content after the '[/INST]' tag.
    
    Args:
    response (str): The full text generated by the model, potentially including the prompt and the generated action.
    actions_list (list): List of possible actions to match against.

    Returns:
    str: The extracted action word or an empty string if no action is found.
    """
    # Split the response by the '[/INST]' tag and take the part after it
    if '[/INST]' in response:
        parts = response.split('[/INST]')
        #print("Parts: ", parts)
        if len(parts) > 1:
            # Only consider the text immediately following the delimiter
            action_part = parts[1].strip()
            # Replace non-alphanumeric characters with spaces, except for hyphens which are important for actions like "move-left"
            cleaned_action_part = ''.join([char if char.isalnum() or char == '-' else ' ' for char in action_part])
            # Normalize spaces to ensure no double spaces mess up the split
            cleaned_action_part = ' '.join(cleaned_action_part.split())
            # Check for multi-word actions first
            #print("Cleaned Action Part: ", cleaned_action_part)
            for action in sorted(actions_list, key=len, reverse=True):  # Sort actions by length to match longer ones first
                action_words = action.replace('-', ' ').lower()  # Replace hyphens with spaces for matching
                if action_words in cleaned_action_part.lower():
                    return action
    return ""


# Function to generate action based on model output
def get_action(obs):
    observer.observe({"frame": obs})
    context = observer.context_prompt()
    action_descriptions = {
        "punch": "a quick attack that deals moderate damage to the opponent if close enough.",
        "kick": "a powerful attack with longer reach than a punch but slightly slower execution.",
        "move left": "shifts your position to the left, potentially avoiding an opponent's attack.",
        "move right": "shifts your position to the right, potentially avoiding an opponent's attack.",
        "crouch": "lowers your stance, dodging high attacks and preparing for defensive or low attacks.",
        "crouch right": "moves right while crouched, evading high attacks and positioning for a counter.",
        "crouch left": "moves left while crouched, evading high attacks and positioning for a counter.",
        "jump": "leaps upward, avoiding low attacks and creating opportunities for aerial assaults.",
        "jump right": "jumps to the right, covering distance and evading low threats.",
        "jump left": "jumps to the left, covering distance and evading low threats."
    }

    action_list_description = "Here are your possible movements and their effects: "
    for action, description in action_descriptions.items():
        action_list_description += f"\n- {action.capitalize()}: {description}"
    prompt = f"[INST] You are playing Street Fighter, your goal is to defeat the opponent. This is the current game state: {context} Your available movements are in this list: [punch, kick, move left, move right, crouch, crouch right, crouch left, jump, jump right, jump left]. {action_descriptions}. Pick one best movement to take from the list. Just constrain your answer to one word such as 'punch' .[/INST]"
    actions_list = ["punch", "kick", "move left", "move right", "crouch", "crouch right", "crouch left", "jump", "jump right", "jump left"]
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    outputs = model.generate(**inputs, do_sample=True, max_new_tokens=10)
    action_text = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
    extracted_action = extract_action_from_response(action_text, actions_list)
    #print("extract Action: ", extracted_action)
    return extracted_action

# Main Loop for Inference
num_episodes = NUM_EPISODES
episode_reward_sum = 0
num_victory = 0

tokenizer.pad_token_id = tokenizer.eos_token_id

for episode in range(num_episodes):
    obs = env.reset()

    if RESET_ROUND:
        obs = env.reset()

    done = False
    total_reward = 0

    while not done:
        action_text = get_action(obs)
        #print("Action: ", action_text)
        actions = get_llm_actions(action_text.lower())  
        for action in actions:
            obs, reward, done, info = env.step(action)
    
        if reward != 0:
            total_reward += reward
            print("Reward: {:.3f}, playerHP: {}, enemyHP:{}".format(reward, info['agent_hp'], info['enemy_hp']))
        
        if info['enemy_hp'] < 0 or info['agent_hp'] < 0:
            done = True

    if info['enemy_hp'] < 0:
        print("Victory!")
        num_victory += 1

    print("Total reward: {}\n".format(total_reward))
    episode_reward_sum += total_reward

    if not RESET_ROUND:
        while info['enemy_hp'] < 0 or info['agent_hp'] < 0:
        # Inter scene transition. Do nothing.
            obs, reward, done, info = env.step([0] * 12)
            env.render()

env.close()
print("Winning rate: {}".format(1.0 * num_victory / num_episodes))

print("Average reward for {}: {}".format(MODEL_NAME, episode_reward_sum/num_episodes))